version: '3.8'

services:
  timescaledb:
    image: timescale/timescaledb:latest-pg14
    container_name: timescaledb
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: gdp_db
    volumes:
      - ./docker/timescale:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - kafka-net
  grafana:
    image: grafana/grafana-enterprise
    container_name: grafana
    restart: unless-stopped
    ports:
      - '3000:3000'
    volumes:
      - ./docker/grafana:/var/lib/grafana
    networks:
      - kafka-net

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    restart: unless-stopped
    ports:
      - "9092:9092" # external/host access (mapped)
      - "9093:9093" # controller (optional to expose)
    environment:
      # KRaft / broker settings
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      CLUSTER_ID: Z4Y2B9T5QH7D1A6XK3C2V7
      KAFKA_BROKER_ID: 1

      # Bind 3 listeners inside the container
      KAFKA_LISTENERS: "EXTERNAL://0.0.0.0:9092,INTERNAL://0.0.0.0:9094,CONTROLLER://0.0.0.0:9093"

      KAFKA_ADVERTISED_LISTENERS: "EXTERNAL://localhost:9092,INTERNAL://kafka:9094,CONTROLLER://kafka:9093"

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "INTERNAL"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # small-cluster settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1

    healthcheck:
      # check the internal listener (reachable inside container)
      test: [ "CMD-SHELL", "echo > /dev/tcp/127.0.0.1/9094 || exit 1" ]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 30s
    networks:
      - kafka-net

  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    restart: unless-stopped
    ports:
      - "8090:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            my-cluster:
              properties:
                # inside compose, AKHQ should use the INTERNAL listener
                bootstrap.servers: "kafka:9094"
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - kafka-net
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/ || exit 1" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
  kafka-connect:
    image: confluentinc/cp-kafka-connect:latest
    container_name: kafka-connect
    ports:
      - "8083:8083" # Kafka Connect REST API port
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9094
      CONNECT_GROUP_ID: kafka-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: kafka-connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/opt/kafka-connect/plugins
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect # Replace with your EC2 instance's public IP
    depends_on:
      - kafka
    networks:
      - kafka-net
    command:
      - bash
      - -c
      - |
        confluent-hub install confluentinc/kafka-connect-jdbc:latest --no-prompt
        /etc/confluent/docker/run

  #---------------------- mongo config ---------------------------
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - ./docker/mongo:/data/db
    networks:
      - kafka-net
    healthcheck:
      test: [ "CMD", "mongo", "--eval", "db.adminCommand('ping')" ]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    restart: always
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_SERVER: mongodb
      ME_CONFIG_MONGODB_PORT: 27017
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: secret
    depends_on:
      - mongodb
    networks:
      - kafka-net

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    networks:
      - kafka-net
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "7077:7077"
      - "8082:8080"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    volumes:
      # Lier le répertoire local actuel au répertoire de travail de Spark
      - ./spark:/opt/bitnami/spark/work
  spark-worker-1:
    image: bitnami/spark:3.5
    container_name: spark-worker-1
    networks:
      - kafka-net
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    ports:
      - "8085:8081"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

volumes:
  grafana-storage: {}
  kafka_data:
  mongo_data:
  kafka-data:


networks:
  kafka-net:
    driver: bridge
